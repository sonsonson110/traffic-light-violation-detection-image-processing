{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1701099105634,
     "user": {
      "displayName": "Nguyễn Phúc Sơn",
      "userId": "00693537287813368192"
     },
     "user_tz": -420
    },
    "id": "oTsfKeW3IoID"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import re\n",
    "from PIL import Image\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1701099105634,
     "user": {
      "displayName": "Nguyễn Phúc Sơn",
      "userId": "00693537287813368192"
     },
     "user_tz": -420
    },
    "id": "BQn7MvnfIy41"
   },
   "outputs": [],
   "source": [
    "def detect_traffic_light_color(image, rect):\n",
    "    # Extract rectangle dimensions\n",
    "    x, y, w, h = rect\n",
    "    # Extract region of interest (ROI) from the image based on the rectangle\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Convert ROI to HSV color space\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define HSV range for red color\n",
    "    red_lower = np.array([0, 120, 70])\n",
    "    red_upper = np.array([10, 255, 255])\n",
    "\n",
    "    # Define HSV range for yellow color\n",
    "    yellow_lower = np.array([20, 100, 100])\n",
    "    yellow_upper = np.array([30, 255, 255])\n",
    "\n",
    "    # Create binary masks for detecting red and yellow in the ROI\n",
    "    red_mask = cv2.inRange(hsv, red_lower, red_upper)\n",
    "    yellow_mask = cv2.inRange(hsv, yellow_lower, yellow_upper)\n",
    "\n",
    "    # Font details for overlaying text on the image\n",
    "    font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "    font_scale = 1\n",
    "    font_thickness = 2\n",
    "\n",
    "    # Check which color is present based on the masks\n",
    "    if cv2.countNonZero(red_mask) > 0:\n",
    "        text_color = (0, 0, 255)\n",
    "        message = \"Detected Signal Status: Stop\"\n",
    "        color = 'red'\n",
    "    elif cv2.countNonZero(yellow_mask) > 0:\n",
    "        text_color = (0, 255, 255)\n",
    "        message = \"Detected Signal Status: Caution\"\n",
    "        color = 'yellow'\n",
    "    else:\n",
    "        text_color = (0, 255, 0)\n",
    "        message = \"Detected Signal Status: Go\"\n",
    "        color = 'green'\n",
    "\n",
    "    # Overlay the detected traffic light status on the main image\n",
    "    cv2.putText(image, message, (15, 70), font, font_scale+0.5, text_color, font_thickness+1, cv2.LINE_AA)\n",
    "    # Add a separator line\n",
    "    cv2.putText(image, 34*'-', (10, 115), font, font_scale, (255,255,255), font_thickness, cv2.LINE_AA)\n",
    "\n",
    "    # Return the modified image and detected color\n",
    "    return image, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701099105634,
     "user": {
      "displayName": "Nguyễn Phúc Sơn",
      "userId": "00693537287813368192"
     },
     "user_tz": -420
    },
    "id": "dOMFgm7JJep-"
   },
   "outputs": [],
   "source": [
    "class LineDetector:\n",
    "    def __init__(self, num_frames_avg=10):\n",
    "        # Initialize two deque queues to hold y-coordinate values across frames\n",
    "        self.y_start_queue = deque(maxlen=num_frames_avg)\n",
    "        self.y_end_queue = deque(maxlen=num_frames_avg)\n",
    "\n",
    "\n",
    "    def detect_white_line(self, frame, color,\n",
    "                          slope1=0.03, intercept1=920, slope2=0.03, intercept2=770, slope3=-0.8, intercept3=2420):\n",
    "\n",
    "        # Function to map color names to BGR values\n",
    "        def get_color_code(color_name):\n",
    "            color_codes = {\n",
    "                'red': (0, 0, 255),\n",
    "                'green': (0, 255, 0),\n",
    "                'yellow': (0, 255, 255)\n",
    "                 }\n",
    "            return color_codes.get(color_name.lower())\n",
    "\n",
    "        frame_org = frame.copy()\n",
    "\n",
    "        # Line equations for defining region of interest (ROI)\n",
    "        def line1(x): return slope1 * x + intercept1\n",
    "        def line2(x): return slope2 * x + intercept2\n",
    "        def line3(x): return slope3 * x + intercept3\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        # Create a mask to spotlight the line's desired area\n",
    "        mask1 = frame.copy()\n",
    "        # Set pixels below the first line to black in mask1\n",
    "        for x in range(width):\n",
    "            y_line = line1(x)\n",
    "            mask1[int(y_line):, x] = 0\n",
    "\n",
    "        mask2 = mask1.copy()\n",
    "        # Set pixels above the second line to black in mask2\n",
    "        for x in range(width):\n",
    "            y_line = line2(x)\n",
    "            mask2[:int(y_line), x] = 0\n",
    "\n",
    "        mask3 = mask2.copy()\n",
    "        # Set pixels to the left of the third line to black in mask3 (final mask)\n",
    "        for y in range(height):\n",
    "            x_line = line3(y)\n",
    "            mask3[y, :int(x_line)] = 0\n",
    "\n",
    "        # Convert the mask to grayscale\n",
    "        gray = cv2.cvtColor(mask3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Perform edge detection\n",
    "        edges = cv2.Canny(gray, 30, 100)\n",
    "\n",
    "        # Perform a dilation and erosion to close gaps in between object edges\n",
    "        dilated_edges = cv2.dilate(edges, None, iterations=1)\n",
    "        edges = cv2.erode(dilated_edges, None, iterations=1)\n",
    "\n",
    "        # Perform Hough Line Transform\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=160, maxLineGap=5)\n",
    "\n",
    "        # Calculate x coordinates for the start and end of the line\n",
    "        x_start = 0\n",
    "        x_end = width - 1\n",
    "\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "\n",
    "                # Calculate line parameters\n",
    "                slope = (y2 - y1) / (x2 - x1 + np.finfo(float).eps)  # Add a small number to avoid division by zero\n",
    "                intercept = y1 - slope * x1\n",
    "\n",
    "                # Calculate corresponding y coordinates\n",
    "                y_start = int(slope * x_start + intercept)\n",
    "                y_end = int(slope * x_end + intercept)\n",
    "\n",
    "                # Add the y_start and y_end values to the queues\n",
    "                self.y_start_queue.append(y_start)\n",
    "                self.y_end_queue.append(y_end)\n",
    "\n",
    "        # Compute the average y_start and y_end values\n",
    "        avg_y_start = int(sum(self.y_start_queue) / len(self.y_start_queue)) if self.y_start_queue else 0\n",
    "        avg_y_end = int(sum(self.y_end_queue) / len(self.y_end_queue)) if self.y_end_queue else 0\n",
    "\n",
    "\n",
    "        # Draw the line\n",
    "        line_start_ratio=0.32\n",
    "        x_start_adj = x_start + int(line_start_ratio * (x_end - x_start))  # Adjusted x_start\n",
    "        avg_y_start_adj = avg_y_start + int(line_start_ratio * (avg_y_end - avg_y_start))  # Adjusted avg_y_start\n",
    "\n",
    "        # Create a mask with the same size as the frame and all zeros (black)\n",
    "        mask = np.zeros_like(frame)\n",
    "\n",
    "        # Draw the line on the mask\n",
    "        cv2.line(mask, (x_start_adj, avg_y_start_adj), (x_end, avg_y_end), (255, 255, 255), 4)\n",
    "\n",
    "        # Determine which color channel(s) to change based on the color argument\n",
    "        color_code = get_color_code(color)\n",
    "        if color_code == (0, 255, 0):  # Green\n",
    "            channel_indices = [1]\n",
    "        elif color_code == (0, 0, 255):  # Red\n",
    "            channel_indices = [2]\n",
    "        elif color_code == (0, 255, 255):  # Yellow\n",
    "            # Yellow in BGR is a combination of green and red channels.\n",
    "            # Here we modify both green and red channels.\n",
    "            channel_indices = [1, 2]\n",
    "        else:\n",
    "            raise ValueError('Unsupported color')\n",
    "\n",
    "        # Change the specified color channels of the frame where the mask is white\n",
    "        for channel_index in channel_indices:\n",
    "            frame[mask[:,:,channel_index] == 255, channel_index] = 255\n",
    "\n",
    "\n",
    "        # Calculate slope and intercept for the average green line\n",
    "        slope_avg = (avg_y_end - avg_y_start) / (x_end - x_start + np.finfo(float).eps)\n",
    "        intercept_avg = avg_y_start - slope_avg * x_start\n",
    "\n",
    "        # Create a mask with the pixels above the green line set to black\n",
    "        mask_line = np.copy(frame_org)\n",
    "        for x in range(width):\n",
    "            y_line = slope_avg * x + intercept_avg - 35\n",
    "            mask_line[:int(y_line), x] = 0  # set pixels above the line to black\n",
    "\n",
    "        return frame, mask_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701099105634,
     "user": {
      "displayName": "Nguyễn Phúc Sơn",
      "userId": "00693537287813368192"
     },
     "user_tz": -420
    },
    "id": "WxXj_5pFJkQe"
   },
   "outputs": [],
   "source": [
    "def extract_license_plate(frame, mask_line):\n",
    "    # Convert the image to grayscale (Haar cascades are typically trained on grayscale images)\n",
    "    gray = cv2.cvtColor(mask_line, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply CLAHE to equalize the histogram\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "\n",
    "    # Erode the image using a 2x2 kernel to remove noise\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    gray = cv2.erode(gray, kernel, iterations=1)\n",
    "\n",
    "    # Find the bounding box of non-black pixels\n",
    "    non_black_points = cv2.findNonZero(gray)\n",
    "    x, y, w, h = cv2.boundingRect(non_black_points)\n",
    "\n",
    "    # Calculate the new width of the bounding box, excluding 30% on the right side\n",
    "    w = int(w * 0.7)\n",
    "\n",
    "    # Crop the image to the bounding box\n",
    "    cropped_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "    # Detect license plates in the image (this returns a list of rectangles)\n",
    "    license_plates = license_plate_cascade.detectMultiScale(cropped_gray, scaleFactor=1.07, minNeighbors=15, minSize=(20, 20))\n",
    "\n",
    "    # List to hold cropped license plate images\n",
    "    license_plate_images = []\n",
    "\n",
    "    # Loop over the license plates\n",
    "    for (x_plate, y_plate, w_plate, h_plate) in license_plates:\n",
    "        # Draw a rectangle around the license plate in the original frame (here you need the original coordinates)\n",
    "        cv2.rectangle(frame, (x_plate + x, y_plate + y), (x_plate + x + w_plate, y_plate + y + h_plate), (0, 255, 0), 3)\n",
    "\n",
    "        # Crop the license plate and append it to the list (here x_plate and y_plate are relative to cropped_gray)\n",
    "        license_plate_image = cropped_gray[y_plate:y_plate+h_plate, x_plate:x_plate+w_plate]\n",
    "        license_plate_images.append(license_plate_image)\n",
    "\n",
    "    return frame, license_plate_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701099105634,
     "user": {
      "displayName": "Nguyễn Phúc Sơn",
      "userId": "00693537287813368192"
     },
     "user_tz": -420
    },
    "id": "gnw-mF0zKQPT"
   },
   "outputs": [],
   "source": [
    "def apply_ocr_to_image(license_plate_image):\n",
    "    # Threshold the image\n",
    "    _, img = cv2.threshold(license_plate_image, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Convert OpenCV image format to PIL Image format for pytesseract\n",
    "    pil_img = Image.fromarray(img)\n",
    "\n",
    "    # Use pytesseract to extract text from the image\n",
    "    full_text = pytesseract.image_to_string(pil_img, config='--psm 6')\n",
    "\n",
    "    return full_text.strip()  # Removing any extra white spaces from the ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1701099105634,
     "user": {
      "displayName": "Nguyễn Phúc Sơn",
      "userId": "00693537287813368192"
     },
     "user_tz": -420
    },
    "id": "ZporFmq8KWUb"
   },
   "outputs": [],
   "source": [
    "def draw_penalized_text(frame):\n",
    "    # Set font, scale, thickness, and color\n",
    "    font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "    font_scale = 1\n",
    "    font_thickness = 2\n",
    "    color = (255, 255, 255)  # White color\n",
    "\n",
    "    # Initial position for Y-coordinate\n",
    "    y_pos = 180\n",
    "\n",
    "    # Put title on the frame\n",
    "    cv2.putText(frame, 'Fined license plates:', (25, y_pos), font, font_scale, color, font_thickness)\n",
    "\n",
    "    # Update Y-coordinate position\n",
    "    y_pos += 80\n",
    "\n",
    "    # Loop through all fined license plates\n",
    "    for text in penalized_texts:\n",
    "        # Add fined license plate text on the frame\n",
    "        cv2.putText(frame, '->  '+text, (40, y_pos), font, font_scale, color, font_thickness)\n",
    "\n",
    "        # Update Y-coordinate for next license plate\n",
    "        y_pos += 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 804,
     "status": "ok",
     "timestamp": 1701099106432,
     "user": {
      "displayName": "Nguyễn Phúc Sơn",
      "userId": "00693537287813368192"
     },
     "user_tz": -420
    },
    "id": "jaPEedecKjZF"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # # Ensure the database and table exist\n",
    "    # create_database_and_table(DB_HOST, DB_USER, DB_PASSWORD, DB_NAME)\n",
    "\n",
    "    # # Clear the license plates from the previous run. (Comment out this line if desired!)\n",
    "    # clear_license_plates(DB_HOST, DB_USER, DB_PASSWORD, DB_NAME)\n",
    "\n",
    "    # Load the trained Haar Cascade\n",
    "    license_plate_cascade = cv2.CascadeClassifier('haarcascade_russian_plate_number.xml')\n",
    "\n",
    "    # Create a list to store unique penalized license plate texts\n",
    "    penalized_texts = []\n",
    "\n",
    "    # Open the video file\n",
    "    vid = cv2.VideoCapture('traffic_video.mp4')\n",
    "\n",
    "    # Create detector object\n",
    "    detector = LineDetector()\n",
    "\n",
    "    # Loop through each frame in the video\n",
    "    while True:\n",
    "        # Read frame\n",
    "        ret, frame = vid.read()\n",
    "\n",
    "        # Break if frame is not returned\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Assuming rect is the rectangle where the traffic light is located\n",
    "        rect = (1700, 40, 100, 250)\n",
    "\n",
    "        # Detect traffic light color\n",
    "        frame, color = detect_traffic_light_color(frame, rect)\n",
    "\n",
    "        # Detect white line\n",
    "        frame, mask_line = detector.detect_white_line(frame, color)\n",
    "\n",
    "        # Process the frame if the light is red\n",
    "        if color == 'red':\n",
    "            # Extract license plate\n",
    "            frame, license_plate_images = extract_license_plate(frame, mask_line)\n",
    "\n",
    "            # Process each detected license plate\n",
    "            for license_plate_image in license_plate_images:\n",
    "                # Apply OCR to the license plate image\n",
    "                text = apply_ocr_to_image(license_plate_image)\n",
    "\n",
    "                # Add the detected license plate to the list if it matches the pattern and is not already in the list\n",
    "                if text is not None and re.match(\"^[A-Z]{2}\\s[0-9]{3,4}$\", text) and text not in penalized_texts:\n",
    "                    penalized_texts.append(text)\n",
    "                    print(f\"\\nFined license plate: {text}\")\n",
    "\n",
    "                    # Plot the license plate image\n",
    "                    plt.figure()\n",
    "                    plt.imshow(license_plate_image, cmap='gray')\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "\n",
    "                    # # Update the database with the license plate violation\n",
    "                    # update_database_with_violation(text, DB_HOST, DB_USER, DB_PASSWORD, DB_NAME)\n",
    "\n",
    "        # Draw the penalized text onto the frame if there is any\n",
    "        if penalized_texts:\n",
    "            draw_penalized_text(frame)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # # Break if ESC key is pressed (uncomment the following line when running on a local system with GUI support)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    # Release the video\n",
    "    vid.release()\n",
    "\n",
    "    # Close all OpenCV windows (uncomment the following line when running on a local system with GUI support)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # # Print all the violations from the database\n",
    "    # print_all_violations(DB_HOST, DB_USER, DB_PASSWORD, DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "executionInfo": {
     "elapsed": 160916,
     "status": "ok",
     "timestamp": 1701099267346,
     "user": {
      "displayName": "Nguyễn Phúc Sơn",
      "userId": "00693537287813368192"
     },
     "user_tz": -420
    },
    "id": "UYThobgzOYs-",
    "outputId": "be1ff0f5-783e-4227-9085-6ea52c028f26"
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJkathIceyJc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPLedAQkQzwrvkzrXQ+USjg",
   "mount_file_id": "1w4JMWUvBxYAYaa7zvOFA-Iusd5KU9sAy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
